{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.io import imread, imread_collection_wrapper, concatenate_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from helpers.utils import load_image, tif_to_rgb\n",
    "from config import TRAIN_PATH, VALIDATION_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread_tiff_rgb_nir(fname, *args, **kwargs):\n",
    "    \"\"\"returns tiff image with 4 channels (RGB + NIR)\"\"\"\n",
    "    im = imread(fname, *args, **kwargs)\n",
    "    # re-indexing is needed because channels are stored as b,g,r,nir\n",
    "    return im[:, :, [2,1,0,3]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file_pattern = \"*.tif\"\n",
    "train_imgs_path = os.path.join(TRAIN_PATH, img_file_pattern)\n",
    "\"\"\"\n",
    "it is necessary to create custom imread collection function which reads images with the 'imread' function\n",
    "in order to obtain the raw values from the tif image. \n",
    "The default imread_collection function returns images that are uncorrectly scaled between 0 and 255\n",
    "\"\"\"\n",
    "imread_collection_custom = imread_collection_wrapper(imread_tiff_rgb_nir)\n",
    "train_imgs = imread_collection_custom(train_imgs_path, conserve_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spectral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFeatureExtractor(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.pixels_axis = (1, 2)\n",
    "    \n",
    "    def fit(self, imgs, y=None):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def transform(self, imgs, y=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SpectralFeatureExtractor(BaseFeatureExtractor):\n",
    "    \"\"\"\n",
    "    extracts mean and standard deviation of every color channel in the image (RGB)\n",
    "    and the brightness, where brightness is defined as the mean of all color channels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs : numpy.ndarray\n",
    "           set of images, each with 4 channels (R,G,B,NIR)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, imgs, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, imgs, y=None):\n",
    "        imgs = imgs[:, :, :, :3] # extract color channels\n",
    "        rgb_means = np.mean(imgs, axis=self.pixels_axis)\n",
    "        brightness = np.mean(rgb_means, axis=1)\n",
    "        brightness = np.reshape(brightness, (-1, 1))\n",
    "        rgb_sds = np.std(imgs, axis=self.pixels_axis)\n",
    "\n",
    "        return np.concatenate((rgb_means, brightness, rgb_sds), axis=1)\n",
    "\n",
    "class NDVIFeatureExtractor(BaseFeatureExtractor):\n",
    "    \"\"\"\n",
    "    extracts normalized difference vegatation index from multispectral image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs : numpy.ndarray\n",
    "           set of images, each with 4 channels (R,G,B,NIR)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, imgs, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, imgs, y=None):\n",
    "        red = imgs[:, :, :, 0]\n",
    "        nir = imgs[:, :, :, 3]\n",
    "\n",
    "        ndvi = (nir-red)/(nir+red)\n",
    "        \n",
    "        # scale ndvi between -1 and 1\n",
    "        # scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
    "        # ndvi = scaler.fit_transform(ndvi)\n",
    "\n",
    "        ndvi_means = np.mean(ndvi, axis=self.pixels_axis)\n",
    "        ndvi_sds = np.std(ndvi, axis=self.pixels_axis)\n",
    "        ndvi_means = np.reshape(ndvi_means, (-1, 1))\n",
    "        ndvi_sds = np.reshape(ndvi_sds, (-1, 1))\n",
    "        return np.concatenate((ndvi_means, ndvi_sds), axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"spectral\", SpectralFeatureExtractor()),\n",
    "    (\"ndvi\", NDVIFeatureExtractor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = concatenate_images(train_imgs[:3])\n",
    "features = feature_pipeline.fit_transform(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48050572, 0.47540455, 0.38136045])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
