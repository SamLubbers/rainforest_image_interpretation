{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import TransformerMixin\n",
    "from skimage.io import concatenate_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from config import DATASETS_PATH, TRAIN_PATH, VALIDATION_PATH\n",
    "from helpers.utils import extract_label_values, load_image_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = load_image_collection(TRAIN_PATH)\n",
    "validation_imgs = load_image_collection(VALIDATION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spectral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move classes extracting features to separate python file\n",
    "class BaseFeatureExtractor(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.pixels_axis = (1, 2)\n",
    "    \n",
    "    def fit(self, imgs, y=None):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def transform(self, imgs, y=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SpectralFeatureExtractor(BaseFeatureExtractor):\n",
    "    \"\"\"\n",
    "    extracts mean and standard deviation of every color channel in the image (RGB)\n",
    "    and the brightness, where brightness is defined as the mean of all color channels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs : numpy.ndarray (np.float)\n",
    "           set of images, each with 4 channels (B, G, R, NIR)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, imgs, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, imgs, y=None):\n",
    "        imgs = imgs[:, :, :, :3] # extract color channels\n",
    "        rgb_means = np.mean(imgs, axis=self.pixels_axis)\n",
    "        brightness = np.mean(rgb_means, axis=1)\n",
    "        brightness = np.reshape(brightness, (-1, 1))\n",
    "        rgb_sds = np.std(imgs, axis=self.pixels_axis)\n",
    "\n",
    "        return np.concatenate((rgb_means, brightness, rgb_sds), axis=1)\n",
    "\n",
    "class NDVIFeatureExtractor(BaseFeatureExtractor):\n",
    "    \"\"\"\n",
    "    extracts normalized difference vegatation index from multispectral image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs : numpy.ndarray (np.float)\n",
    "           set of images, each with 4 channels (B, G, R, NIR)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, imgs, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, imgs, y=None):\n",
    "        red = imgs[:, :, :, 2]\n",
    "        nir = imgs[:, :, :, 3]\n",
    "\n",
    "        ndvi = np.divide(nir-red, nir+red)\n",
    "        \n",
    "        ndvi_means = np.mean(ndvi, axis=self.pixels_axis)\n",
    "        ndvi_sds = np.std(ndvi, axis=self.pixels_axis)\n",
    "        ndvi_means = np.reshape(ndvi_means, (-1, 1))\n",
    "        ndvi_sds = np.reshape(ndvi_sds, (-1, 1))\n",
    "        return np.concatenate((ndvi_means, ndvi_sds), axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureUnion(transformer_list=[\n",
    "    (\"spectral\", SpectralFeatureExtractor()),\n",
    "    (\"ndvi\", NDVIFeatureExtractor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs_collection, feature_extractor, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Extracts from imgs_collection the set of features specified in feature_extractor.\n",
    "    Extracts the features in batches because it is unviable to load all images at once into memory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs_collection : skimage.ImageCollection\n",
    "                      collection of images from which we want to extract the features\n",
    "    feature_extractor: sklearn transformer\n",
    "                       transformers that extract features from images\n",
    "    batch_size: number of images to extract features from at each iteration\n",
    "                a deafult value of 1000 loads approx. 0.5 GB into memory for this dataset\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    features: numpy.ndarray (np.float64)\n",
    "              set of features extracted from the image, \n",
    "              with one row for each image and one column for each feature\n",
    "    \"\"\"\n",
    "    \n",
    "    n_images = len(imgs_collection)\n",
    "    # get number of total features\n",
    "    features_im0 = feature_extractor.fit_transform(concatenate_images(imgs_collection[:1]))\n",
    "    n_features = np.shape(features_im0)[1]\n",
    "    # create array for features\n",
    "    features = np.zeros([n_images, n_features])\n",
    "    features[0, :] = features_im0\n",
    "    for i in range(1, n_images, batch_size):\n",
    "        imgs_batch = concatenate_images(imgs_collection[i:i+batch_size])\n",
    "        # casting is required for feature extraction! \n",
    "        # else the default uint16 produces errors in the computations\n",
    "        imgs_batch = imgs_batch.astype('float64', casting='safe')\n",
    "        features_batch = feature_extractor.fit_transform(imgs_batch)\n",
    "        features[i:i+batch_size, :] = features_batch\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(train_imgs, feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features = extract_features(validation_imgs, feature_extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(os.path.join(DATASETS_PATH, 'train_labels.csv'))\n",
    "train_labels = extract_label_values(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = classifier.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.644e+03, 5.993e+03, 2.271e+03, 1.219e+03, 9.230e+02, 1.125e+03,\n",
       "       2.300e+02, 2.000e+02, 3.370e+02, 3.310e+02, 6.000e+00, 0.000e+00,\n",
       "       2.800e+01, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels_df = pd.read_csv(os.path.join(DATASETS_PATH, 'validation_labels.csv'))\n",
    "validation_labels = extract_label_values(validation_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(labels, predictions, beta=2):\n",
    "    mean_f2 = fbeta_score(labels, predictions, beta, average='samples')\n",
    "    per_class_f2 = fbeta_score(labels, predictions, beta, average=None)\n",
    "    return mean_f2, per_class_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8096, 19)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_name                train_0\n",
       "tags                 primary haze\n",
       "primary                         1\n",
       "clear                           0\n",
       "agriculture                     0\n",
       "road                            0\n",
       "water                           0\n",
       "partly_cloudy                   0\n",
       "cultivation                     0\n",
       "habitation                      0\n",
       "haze                            1\n",
       "cloudy                          0\n",
       "bare_ground                     0\n",
       "selective_logging               0\n",
       "artisinal_mine                  0\n",
       "blooming                        0\n",
       "slash_burn                      0\n",
       "conventional_mine               0\n",
       "blow_down                       0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels_df.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "baseline_predictions_df = validation_labels_df.copy(deep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_name                train_0\n",
       "tags                 primary haze\n",
       "primary                         1\n",
       "clear                           0\n",
       "agriculture                     0\n",
       "road                            0\n",
       "water                           0\n",
       "partly_cloudy                   0\n",
       "cultivation                     0\n",
       "habitation                      0\n",
       "haze                            1\n",
       "cloudy                          0\n",
       "bare_ground                     0\n",
       "selective_logging               0\n",
       "artisinal_mine                  0\n",
       "blooming                        0\n",
       "slash_burn                      0\n",
       "conventional_mine               0\n",
       "blow_down                       0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_predictions_df.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Samu/anaconda/envs/vision/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Samu/anaconda/envs/vision/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "mean_f2, per_class_f2 = evaluate_performance(validation_labels, validation_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
