{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data is split into training and validation set so that model can be evaluated without submitting test set predictions on Kaggle and using custom evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from config import DATASETS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_labels_path = os.path.join(DATASETS_PATH, 'train_validation_labels.csv')\n",
    "df_labels = pd.read_csv(csv_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, validation_set = train_test_split(df_labels, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate whether the labels are properly distributed among train and validations sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distrbution(df):\n",
    "    n_instances = len(df)\n",
    "    label_count = df.iloc[:, 2:].sum()\n",
    "    return label_count / n_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary              7532\n",
       "clear                5737\n",
       "agriculture          2448\n",
       "road                 1638\n",
       "water                1491\n",
       "partly_cloudy        1442\n",
       "cultivation           910\n",
       "habitation            771\n",
       "haze                  516\n",
       "cloudy                401\n",
       "bare_ground           180\n",
       "selective_logging      67\n",
       "artisinal_mine         66\n",
       "blooming               62\n",
       "slash_burn             47\n",
       "conventional_mine      17\n",
       "blow_down              22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set.iloc[:, 2:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether the labels are properly distributed\n",
    "original_distribution = calculate_distrbution(df_labels)\n",
    "train_distribution = calculate_distrbution(train_set)\n",
    "validation_distribution = calculate_distrbution(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %difference in label distribution between original and new training set\n",
    "diff_training = pd.concat([original_distribution,\n",
    "          train_distribution], axis = 1).T.pct_change().iloc[1, :]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %difference in label distribution between original training set and validation set\n",
    "diff_validation = pd.concat([original_distribution,\n",
    "          validation_distribution], axis = 1).T.pct_change().iloc[1, :]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = pd.concat([original_distribution, diff_training, diff_validation], axis=1)\n",
    "df_diff.columns = ['original distribution', '% diff. training', '% diff. validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_round = df_diff.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  original distribution &  \\% diff. training &  \\% diff. validation \\\\\n",
      "\\midrule\n",
      "primary           &                  0.927 &            -0.097 &               0.389 \\\\\n",
      "clear             &                  0.702 &            -0.223 &               0.891 \\\\\n",
      "agriculture       &                  0.304 &             0.153 &              -0.611 \\\\\n",
      "road              &                  0.199 &            -0.368 &               1.472 \\\\\n",
      "water             &                  0.183 &            -0.148 &               0.591 \\\\\n",
      "partly\\_cloudy     &                  0.179 &             0.176 &              -0.705 \\\\\n",
      "cultivation       &                  0.111 &            -0.407 &               1.628 \\\\\n",
      "habitation        &                  0.090 &            -1.331 &               5.325 \\\\\n",
      "haze              &                  0.067 &             1.085 &              -4.341 \\\\\n",
      "cloudy            &                  0.052 &             1.006 &              -4.023 \\\\\n",
      "bare\\_ground       &                  0.021 &            -1.101 &               4.406 \\\\\n",
      "selective\\_logging &                  0.008 &             0.368 &              -1.473 \\\\\n",
      "artisinal\\_mine    &                  0.008 &             0.664 &              -2.657 \\\\\n",
      "blooming          &                  0.008 &             1.657 &              -6.629 \\\\\n",
      "slash\\_burn        &                  0.005 &            -3.109 &              12.437 \\\\\n",
      "conventional\\_mine &                  0.002 &             3.751 &             -15.002 \\\\\n",
      "blow\\_down         &                  0.002 &            -3.061 &              12.242 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_diff_round.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move images in the training set to new directories corresponding to the new training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file names\n",
    "training_images = train_set[['image_name']].iloc[:, 0]\n",
    "validation_images = validation_set[['image_name']].iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CODE IS NOT NEEDED ANYMORE ONCE THE FILES HAVE BEEN MOVED\n",
    "\n",
    "# create sub directories\n",
    "original_imgs_dir = os.path.join(DATASETS_PATH, 'train')\n",
    "train_imgs_dir = os.path.join(original_imgs_dir, 'train')\n",
    "validation_imgs_dir = os.path.join(original_imgs_dir, 'validation')\n",
    "\n",
    "if not os.path.exists(train_imgs_dir):\n",
    "    os.makedirs(train_imgs_dir)\n",
    "    \n",
    "if not os.path.exists(validation_imgs_dir):\n",
    "    os.makedirs(validation_imgs_dir)\n",
    "\n",
    "# move images to appropriate directories\n",
    "for img in training_images:\n",
    "    file_name = f'{img}.tif'\n",
    "    old = os.path.join(original_imgs_dir, file_name)\n",
    "    new = os.path.join(train_imgs_dir, file_name)\n",
    "    os.rename(old, new)\n",
    "    \n",
    "for img in validation_images:\n",
    "    file_name = f'{img}.tif'\n",
    "    old = os.path.join(original_imgs_dir, file_name)\n",
    "    new = os.path.join(validation_imgs_dir, file_name)\n",
    "    os.rename(old, new)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reorder dataframes in file name numerical order. This is important during training when the training data image features must match the appropriate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_sorted = train_set.sort_index()\n",
    "validation_set_sorted = validation_set.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output training and validation labels to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_sorted.to_csv(os.path.join(DATASETS_PATH, 'train_labels.csv'), index=False)\n",
    "validation_set_sorted.to_csv(os.path.join(DATASETS_PATH, 'validation_labels.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
